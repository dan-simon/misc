This is mostly for me to look back on at the end of 2024. Don't take it that seriously. I don't know much.

Predictions (for end of 2024):
- Top LLM performance:
  - Current GPT-4 is still near-best: 10%
  - Something noticeably better exists, but by less than the 3.5-4 gap: 30%
  - Something better exists, by roughly the 3.5-4 gap: 40%
  - Something better exists, by slightly more than the 3.5-4 gap: 15%
  - Something better exists, by dramatically more than the 3.5-4 gap: 5%
- Other predictions:
  - Transformative AI (20% unemployment or something with equivalent impact): 2%
  - There are no types of question that most humans can answer but AIs can't: 10%
  - New type of AI capability: 50%

Clarifications:
- As far as I remember, GPT-3 made errors a lot more than GPT-3.5, and could barely have any sort of cohesive response making a specific point. I would say GPT 3-3.5 is a bigger gap than 3-4.
- In my experience, the 3.5-4 gap is doing things better and being less likely to hallucinate/make other weird logical errors. If weird logical errors are basically entirely fixed, that in itself is probably at least "roughly the 3.5-4 gap". If making creative leaps is basically solved, that probably counts as at least "slightly more than the 3.5-4 gap".
- I may try to create some sort of (somewhat subjective, but less so) 10-question benchmark, or something.
  - Possible topics
    - DP puzzlehunt
    - Simple loop
    - Advent-of-code-esque task
    - Cryptic clues
    - Math problem
    - Geography problem? Geography often seems like a confusing area, probably due to spacial reasoning issues.
    - Nth letter of words
    - Codes?

- Transformative AI would also likely include "most people in the community I'm in find themselves often visibly using AI in most aspects of their lives".
- "There are no types of question that most humans can answer but AIs can't" excludes non-text-based things (multidimensional puzzles are still fine though, as long as they can be presented in text in such a way that most humans can solve them), things based on lived experience, and content filters.
- "New type of AI capability" is something like AI image creation was in 2022. It doesn't actually have to be new, it just has to become a lot more prominent than it was before. 2023 didn't have any of these (for example, coding had already emerged earlier, and browsing the web was similar enough to using search engines that I don't think people really cared). This doesn't have to be LLMs.
- Candidates: If AI music became as common as AI art now is, it'd count. If AI made huge progress in math, it'd also count.