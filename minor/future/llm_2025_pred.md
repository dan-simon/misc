This is mostly for me to look back on at the end of 2025. Don't take it that seriously. I don't know much and didn't spend much time making this. For AI read LLM.

Predictions (for end of 2025):
- Top LLM performance:
  - This is so hard to define, and LMSYS general leaderboard actually seems mostly reasonable to me, so I'll go by it. Predictions are all conditional on it still operating and not changing the scale. I guess I'll round exact 00/50 ratings into the above category, so 1600 is in the top bucket, 1550 is in the second-to-top, etc.
  - LMSYS highest rating below 1400: 5%
  - LMSYS highest rating between 1400 and 1450: 15%
  - LMSYS highest rating between 1450 and 1500: 20%
  - LMSYS highest rating between 1450 and 1500: 20%
  - LMSYS highest rating between 1550 and 1600: 15%
  - LMSYS highest rating above 1600: 25%
- Other predictions:
  - Transformative AI (20% unemployment or something with equivalent impact): 3%
  - There are no types of question that most humans can answer but AIs can't (same caveats as last year): 15%
- Reasoning:
  - Some o3 model is released publically: 80%
  - Some o3 model is released publically at <=40$/month (possibly with lower limits): 50%
  - Anthropic releases a reasoning model: 60%
  - AI with reasoning is higher on LMSYS than AI without reasoning: 40%
  - AI with reasoning feels better at tasks I currently care about (mainly math/programming) than AI without reasoning: 75%
  - There's a <=40$/month-to-access version of o1 that can run code (not just reason through the steps), and it doesn't seem much worse: 70% (just seems obvious to build in, and very helpful, but maybe it breaks the training process and no fix is found)
- Agency:
  - (By "people use" I mean it's used often enough you hear about it as more than a novelty very often, rather than just for its own sake.)
  - *People use AI to write docs/code and just let it keep running, rather than the current prompt-and-reprompt-if-needed framework or even run-this-set-of-tasks framework that the current Google Doc generation probably uses: 20%
  - People use Claude computer use or equivalent: 40%
  - *People use Claude computer use or equivalent without walking the AI through most steps: 20%
  - Some agency advance (includes either of the two starred predictions and possibly other stuff): 40%
- AI capabilities, math/programming/science:
  - The FrontierMath 25% doesn't have some known-at-end-of-year huge caveat: 85%
  - AI solves a Millenium problem: 7%
  - AI solves some similarly huge open math problem: 20%
  - AI becomes a key part of math research (more than just typesetting/what WolframAlpha already does, with lots of people saying they use it for this or it being otherwise clear): 30%
  - AI becomes a key part of science research: 20%
  - AI becomes fully ~top-10 at hard coding contests (codeforces 3500 or something I'm convinced is equivalent): 60%
  - <=40$/month-to-access AI becomes fully ~top-10 at hard coding contests: 30%
- Other AI capabilities:
  - Robots don't become ubiquitous or incessantly talked about the way AI art/LLMs were: 90%
  - AI writing remains roughly as common as it is (i.e., slightly less than AI art): 80%
  - AI (visual) art remains roughly as common as it is (i.e., very, but people do sometimes human-make images too): 90%
  - AI music becomes almost as big as AI art, accounting for there being less music than art (this is close to "when you see a music audio file/music video while surfing the web, there's a >=10% chance of it being AI music"): 15%
  - Some other (not math/science/programming/writing/pictures/music/robotics/agency) surprising new AI capability: 15%
